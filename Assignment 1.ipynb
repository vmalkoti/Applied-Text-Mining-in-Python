{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'sShe tries to follow several dietary rules including avoiding \"junk foods\" like chips  ice cream, trying not to eat more than 2,000 kcals/day, and eating at roughly the same time every day.  She also purges by self-induced vomiting \"when I feel like I\\'m eating too much.\"  Typically this is after breakfast and dinner.  She reports that she has been vomiting 2x/day \"most days\" for the past 3 months, consistent with \"extreme\" to \"severe\" severity of compensatory behaviors per DSM-5.  She notes that she previously vomited 4-6x/day between ages 11-16 yo (i.e., before she received any treatment for her eating disorder).  She previously took laxatives 2x/day from ages 14-17, but the last episode was >1 year ago (stopped b/c \"they were wicked expensive\").  She has also taken diet pills (last episode in Feb 1993) but stopped b/c \"they weren\\'t working.\"  No history of diuretic misuse.\\n'"
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df[272]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0        9\n1       84\n2        2\n3       53\n4       28\n      ... \n495    231\n496    141\n497    186\n498    161\n499    413\nName: index, Length: 500, dtype: int64"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "import re\n",
    "import datetime\n",
    "import dateutil.parser as dparser\n",
    "import numpy as np\n",
    "\n",
    "def get_date_from_text(txt):\n",
    "    p1 = r'\\b0?(\\d?\\d)[/-](\\d?\\d)[/-](\\d{2}|\\d{4})\\b'\n",
    "    p5 = r'\\b0?(\\d?\\d)[/-](\\d{4})\\b'\n",
    "    p2 = r'(\\d?\\d)?[ -]?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z\\.]*[ -]?(\\d?\\d)?[a-z]*,?[ -](\\d{2,4})'\n",
    "    p3 = r'\\b(?<!\\d{3}[ -.]\\d{3}[ -.])\\d{4}\\b'\n",
    "    p4 = r'(?<!\\d{3}[ -.]\\d{3}[ -.])\\d{4}'\n",
    "    txt = txt.replace('Decemeber', 'December').replace('Janaury', 'January')\n",
    "    r = re.search('|'.join([p1, p2, p3, p4, p5]), txt)\n",
    "    dt = r.group(0) if r else ''\n",
    "    dtparsed = dparser.parse(dt.lstrip('0'), default=datetime.datetime(1900, 1, 1), fuzzy=True).date()\n",
    "    return dtparsed\n",
    "\n",
    "\n",
    "def date_sorter():\n",
    "    \n",
    "    # Your code here\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['text'] = df\n",
    "    df2['extracted_date'] = np.vectorize(get_date_from_text)(df2['text'])\n",
    "    #df2['sorted_position'] = \n",
    "    df2 = df2.sort_values(by='extracted_date')\n",
    "    \n",
    "    # https://www.coursera.org/learn/python-text-mining/programming/LvcWI/assignment-1-submission/discussions/threads/AoLX8rSbEeiqnRI0WnAb-A\n",
    "    df2.reset_index(inplace=True)\n",
    "    return df2['index']\n",
    "\n",
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}